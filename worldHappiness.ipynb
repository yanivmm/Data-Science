{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Created on Sun Jul 20 15:07:00 2020\n",
    "\n",
    "@author: YanivMaimon\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#pre\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "############         create datas     ################\n",
    "\n",
    "\n",
    "# first table's path\n",
    "path = r'C:\\Users\\97250\\Desktop\\studied\\R ,python\\Datasets Kaggle\\World Hapiness\\WorldHappiness2015.csv'\n",
    "\n",
    "### tow datas we will work with :\n",
    "\n",
    "        #yearlyData            \n",
    "        #timeData \n",
    "\n",
    "yearlyData =  pd.read_csv(path)\n",
    "timeData = pd.read_csv(path)[['Country','Happiness Score']].set_index('Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#       Add all happiness_Score to 'timeData'\n",
    "\n",
    "\n",
    "for i in range(2015,2020):\n",
    "    addPath = r'C:\\Users\\97250\\Desktop\\studied\\R ,python\\Datasets Kaggle\\World Hapiness\\WorldHappiness' + str(i) + '.csv'\n",
    "    \n",
    "    #try until columns are matching:\n",
    "    try:\n",
    "        try:\n",
    "            addData = pd.read_csv(addPath)[['Country','Happiness Score']]\n",
    "        except:\n",
    "            addData = pd.read_csv(addPath)[['Country','Happiness.Score']]\n",
    "    except:\n",
    "        addData = pd.read_csv(addPath)[['Country or region','Score']]\n",
    "        \n",
    "    # Set unified form and join \n",
    "    addData.columns = ['Country','HappinessScore'+str(i)]\n",
    "    addData = addData.set_index('Country')\n",
    "    timeData = timeData.join(addData,how='inner')\n",
    "\n",
    "#drop column of the initialized data\n",
    "timeData.drop(timeData.columns[0],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####           usefull functions       #######        \n",
    "\n",
    "\n",
    "# agg count function   \n",
    "def agg(colum , c='Happines Score',k =''):  ### d='r' will show relative data.\n",
    "    \n",
    "    \"\"\"\n",
    "    Aggregation function.\n",
    "    \n",
    "    Input:\n",
    "        Colum - string or list of strings.\n",
    "        c - string, kind of column to pick.\n",
    "        k - string, kind of agg. .\n",
    "        \n",
    "    Return:\n",
    "        DataFrame's aggregated form by given column(s).\n",
    "    \"\"\"\n",
    "    \n",
    "    #choose rank or score of happiness \n",
    "    if c == 'r':\n",
    "        c='rank'\n",
    "    \n",
    "    a = yearlyData.groupby(colum)\n",
    "    \n",
    "    # These function change due to the data kind I work with.\n",
    "    if k == 'v':\n",
    "        a = a.var()\n",
    "    else:\n",
    "        a = a.mean()\n",
    "        \n",
    "    if type(colum) != list: # if one column has been given\n",
    "        return a[c].sort_values(ascending=False)\n",
    "    else:\n",
    "        return a[[c]].unstack(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'l':(24,18),'m':(16,12),'s':(12,8)}    \n",
    "  \n",
    "def saver(st):\n",
    "    plt.savefig(r'C:\\Users\\97250\\Desktop\\studied\\R ,python\\Datasets Kaggle\\Outputs data\\WorldHappiness\\'' + st + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "          \n",
    "# visual plots \n",
    "def show(data,s = 'm',st='',save=False):\n",
    "    \"\"\"\n",
    "    Plots Bar chart.\n",
    "    input:\n",
    "        data - DataFrame.\n",
    "        st   - string - what to print in title.\n",
    "        s    - string - Output size.\n",
    "    \"\"\"\n",
    "    \n",
    "    scale = dic[s]\n",
    "    kind = 'line' if len(data.shape)==2 else 'bar' #len(data.shape)==2 means: 2 dimentional data\n",
    "    \n",
    "    data.plot(kind = kind,lw = (scale[0]//4),figsize = scale,fontsize = scale[0]+4)\n",
    "    plt.title(\"\\n \" + st + \": \\n\",fontsize = 2*scale[0])\n",
    "    plt.legend(loc='upper right',prop={'size':1.2*scale[0]})    \n",
    "    if save:\n",
    "        saver(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap function\n",
    "def heat(data,s='m',st='',save=False):\n",
    "    \n",
    "    scale = dic[s]\n",
    "    \n",
    "    sns.set(font_scale = 1.8)\n",
    "    plt.figure(figsize = scale)\n",
    "    sns.heatmap(data = data ,lw=1 ,linecolor = 'white',cmap = 'Reds', annot = True)\n",
    "    plt.title('\\n'+ st +': \\n',fontsize = 2*scale[0])\n",
    "    if save :\n",
    "        saver(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topCountries(top=10):\n",
    "    \n",
    "    \"\"\"\n",
    "    This func return data for top countries throughout time.\n",
    "    \"\"\"\n",
    "    \n",
    "    #top 10 deadly countries\n",
    "    countries = agg('country')[:top].index\n",
    "    print(countries)\n",
    "    #grab aggregated data for these countries\n",
    "    dataOfTop10 = agg(['country']).query(\"country in @countries\")\n",
    "    #unstack data\n",
    "    dataOfTop10 = dataOfTop10.unstack(1)\n",
    "    #remove multiindexes\n",
    "    dataOfTop10 = dataOfTop10.transpose().reset_index(level=0, drop=True).transpose()\n",
    "    #sort by year\n",
    "    dataOfTop10.sort_index(inplace=True)\n",
    "    return dataOfTop10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do notice family column includes 'social-suupport column inside.\n",
    "\n",
    "\n",
    "# show top countries through time\n",
    "\n",
    "top10data = timeData.iloc[:10].transpose()\n",
    "show(top10data,st ='top 10 happy countries through time' ,save=True)\n",
    "\n",
    "################################\n",
    "\n",
    "\n",
    "#this is an interesting one\n",
    "#              lets find most varianted countries through years\n",
    "\n",
    "#varianc ethrough years\n",
    "yearVariance =  timeData.transpose().var()\n",
    "#avg of variance\n",
    "varianceAvg = round(yearVariance.mean(),5)\n",
    "#hifhly varianced countries\n",
    "countriesVarienced = yearVariance[yearVariance>0.7*varianceAvg].index\n",
    "# data of variented countries\n",
    "dataOfTop = yearlyData.query(\"Country in @countriesVarienced\")\n",
    "# agg. by region\n",
    "mostVariencedRegions = dataOfTop.groupby('Region').mean()[['Happiness Rank']]\n",
    "#sort\n",
    "mostVariencedRegions = mostVariencedRegions.sort_values(by= 'Happiness Rank',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######        Machine Learning Section    #######\n",
    "\n",
    "\n",
    "## try to predictit the 'Happiness Rank' of 10% of countries\n",
    "\n",
    "#       preperation\n",
    "\n",
    "yearlyData.set_index('Country',inplace=True)\n",
    "\n",
    "X = yearlyData.drop(['Region', 'Happiness Rank', 'Happiness Score'],axis=1)\n",
    "y = yearlyData['Happiness Score']\n",
    "\n",
    "#   scale\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#cols = X.columns\n",
    "#X = MinMaxScaler().fit_transform(X)\n",
    "#X = pd.DataFrame(X,columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=101)\n",
    "\n",
    "########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#       desicion tree model \n",
    "\n",
    "##from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "#cross_val_score(regressor, X_train, y_train, cv=10)\n",
    "\n",
    "regressor.fit(X_train,y_train)\n",
    "\n",
    "predictions = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "MAE = round(mean_absolute_error(predictions,y_test),5)\n",
    "print('The RMSE is: ' , round(np.sqrt(mean_squared_error(predictions,y_test)),5))\n",
    "print('The MAE  is: ' , round(mean_absolute_error(predictions,y_test),5))\n",
    "\n",
    "\n",
    "######################\n",
    "\n",
    "#           random forest model \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=600)\n",
    "\n",
    "rfr.fit(X_train,y_train)\n",
    "\n",
    "predictions = rfr.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
